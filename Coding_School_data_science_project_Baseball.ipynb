{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNhtDB2582ZVfW8S7s1JW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucaMorocco/Luca-s-room/blob/main/Coding_School_data_science_project_Baseball.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score\n",
        "from sklearn import datasets, model_selection, metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Research question- What makes hall of fame players so great?"
      ],
      "metadata": {
        "id": "8ttJ3QiI82Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions and Libraries import"
      ],
      "metadata": {
        "id": "aQD3ypofCApf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#Base ball data set from caggle upload"
      ],
      "metadata": {
        "id": "uC5Dmu7V9q39",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one = pd.read_csv('/content/500hits.csv',encoding = 'latin-1')\n",
        "df_one.head()"
      ],
      "metadata": {
        "id": "dmb2C3KG_0Gb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one.info()\n",
        "#It seems like there are no missing values,\n",
        "#but there are probably incorrect values\n",
        "# I saw a zero in RBIs, so definitly need to find zeros."
      ],
      "metadata": {
        "id": "6qicBpHnALb_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one.describe()\n",
        "#There are no missing values, but there are some zeros in the RBI category and the strikeout category that need to be fixed."
      ],
      "metadata": {
        "id": "nzpDncxcG_2F",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one.columns"
      ],
      "metadata": {
        "id": "NgVWKJALBjMf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rename={\"PLAYER\":\"Player\",\"YRS\":\"Years Played\", \"G\":\"Games Played\",\n",
        "        \"AB\":\"At Bats\",\"R\":\"Runs\",\"H\":\"Hits\",\"2B\":\"Doubles\",\"3B\":\"Triples\",\n",
        "        \"HR\":\"Home Runs\",\"RBI\":\"Runs Batted In\",\"BB\":\"Walks\"\n",
        "        ,\"SO\":\"Strike Outs\",\"SB\":\"Stolen Bases\",\"CS\":\"Caught Stolen\",\n",
        "        \"BA\":\"Batting Average\",\"HOF\":\"Hall of Fame\"}\n",
        "df_one = df_one.rename(columns= rename)\n",
        "df_one.head()"
      ],
      "metadata": {
        "id": "vXzNyJo9Bsl1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am going to try to start finding the missing data and replacing it.\n",
        "df_one[(df_one['Runs Batted In']<100)]\n",
        "#looks like Runs batted in category is unusable unless\n",
        "#I manually replace all the values or drop the rows with zeros.\n"
      ],
      "metadata": {
        "id": "GiSqAwgHBoed",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will be for strikeouts\n",
        "df_one[(df_one['Strike Outs']<115)]\n",
        "# Strikeouts cannot be use either because the data is incomplete for players\n",
        "# that played in the early 20th or late 19th century\n",
        "#Joe Sewell had the lowest strike out percentage so its safe to say\n",
        "#that most of these numbers are incomplete."
      ],
      "metadata": {
        "id": "T9QhXimXIMxI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one[(df_one['Caught Stolen']<1)]\n",
        "#Too many zeros here too so this column must be dropped as well or all players with zeros must be dropped"
      ],
      "metadata": {
        "id": "juWB9DneWKp6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one[(df_one['Hall of Fame']> 1)]\n",
        "# obviously this value is incorrect should be a one\n",
        "\n"
      ],
      "metadata": {
        "id": "1BVpcmQhWf6B",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one= df_one.drop(columns = ['Runs Batted In','Strike Outs', 'Caught Stolen'], axis = 1)\n",
        "df_one.head()"
      ],
      "metadata": {
        "id": "oKHWWx3KnZhd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one.iloc[160,12]=1\n",
        "df_one.iloc[160,12]\n",
        "#Fixed that datapoint"
      ],
      "metadata": {
        "id": "yyVz6a5oYo3-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to start creating a bunch of different graphs to investigate my data and see if I can discover any trends"
      ],
      "metadata": {
        "id": "0t94JvsNkbn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this data suggests that more at bats will lead to more hits\n",
        "plt.scatter(df_one['At Bats'],df_one['Hits'], alpha = 0.5)\n",
        "plt.title(\"At Bats vs Hits in Professional Baseball Players\")\n",
        "plt.xlabel(\"At Bats\")\n",
        "plt.ylabel(\"Hits\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ejFkEyMXYSmo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one['At Bats'],df_one['Doubles'], alpha = 0.5, color = \"orange\")\n",
        "plt.title(\"At Bats vs Doubles in Professional Baseball Players\")\n",
        "plt.xlabel(\"At Bats\")\n",
        "plt.ylabel(\"Doubles\")\n",
        "plt.show()\n",
        "# A decently linear relationship"
      ],
      "metadata": {
        "id": "Mbenh_qvdj2B",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doubles conform a lot more to the tend of more hits = more doubles\n",
        "plt.scatter(df_one['Hits'],df_one['Doubles'], alpha = 0.5)\n",
        "plt.title(\"Hits vs Doubles in Professional Baseball Players\")\n",
        "plt.xlabel(\"Hits\")\n",
        "plt.ylabel(\"Doubles\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eodc18pyXilk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9U1GGuDhX0GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Its seems like Triples go against the trend of more at hits= more triples, but less severely than home runs\n",
        "plt.scatter(df_one['Hits'],df_one['Triples'], alpha= 0.5)\n",
        "plt.title(\"Hits vs Triples in Professional Baseball Players\")\n",
        "plt.xlabel(\"Hits\")\n",
        "plt.ylabel(\"Triples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P1Z5KXoKVaWH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one['At Bats'],df_one['Triples'], alpha = 0.5, color = \"orange\")\n",
        "plt.title(\"At Bats vs Triples in Professional Baseball Players\")\n",
        "plt.xlabel(\"At Bats\")\n",
        "plt.ylabel(\"Triples\")\n",
        "plt.show()\n",
        "# Like with hits, there is definitly more of a random spread of the data than in the case of doubles"
      ],
      "metadata": {
        "id": "NmRdfQknd2q6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It seems like Home runs go against the trend more hits = more home runs\n",
        "plt.scatter(df_one['Hits'],df_one['Home Runs'], alpha = 0.5)\n",
        "plt.title(\"Hits vs Home Runs in Professional Baseball Players\")\n",
        "plt.xlabel(\"Hits\")\n",
        "plt.ylabel(\"Home Runs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AW8Kk_zWYpuc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one['At Bats'],df_one['Home Runs'], alpha = 0.5, color = \"orange\")\n",
        "plt.title(\"At Bats vs Home Runs in Professional Baseball Players\")\n",
        "plt.xlabel(\"At Bats\")\n",
        "plt.ylabel(\"Home Runs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dHIQ7upfeCpF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I am going to add in hall of fame to the plots to see if any patterns emerge"
      ],
      "metadata": {
        "id": "Rd4xr4XkfaQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This plot is interesting because it shows that players with a high batting average and/or a lot of games played are more likely\n",
        "# to be inducted into the hall of fame\n",
        "\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Games Played'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Batting Average'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Games Played'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Batting Average'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between games played and batting average in profesional baseball players\")\n",
        "plt.xlabel('Games Played')\n",
        "plt.ylabel('Batting Average')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4y9tIG2QZQn7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These graphs are all Batting average in the Y"
      ],
      "metadata": {
        "id": "kSGgGgllszSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['At Bats'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Batting Average'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['At Bats'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Batting Average'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between at bats and batting average in profesional baseball players\")\n",
        "plt.xlabel('At Bats')\n",
        "plt.ylabel('Batting Average')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TX9NpLMCh1Jj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Hits'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Batting Average'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Hits'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Batting Average'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Hits and Batting Average in profesional baseball players\")\n",
        "plt.xlabel('Hits')\n",
        "plt.ylabel('Batting Average')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sRNdA_XSo7qi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These Graphs have Hits i the Y"
      ],
      "metadata": {
        "id": "M3umiBYes4ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Games Played'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Batting Average'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Games Played'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Batting Average'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Games played and Batting Average in profesional baseball players\")\n",
        "plt.xlabel('Games Played')\n",
        "plt.ylabel('Batting Average')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# this plot is super interesting because it suggests that once again longevity is important for hall of fame players. It also\n",
        "# hints that there are other factors that determine if you go to the hall of fame because there is a large overlap betweeen HOF\n",
        "#and Non HOF players"
      ],
      "metadata": {
        "id": "vTq7uE8wgBfx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These Graphs have Doubles in the Y"
      ],
      "metadata": {
        "id": "tjsV18qns-NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['At Bats'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Doubles'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['At Bats'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Doubles'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between at bats and doubles in profesional baseball players\")\n",
        "plt.xlabel('At Bats')\n",
        "plt.ylabel('Doubles')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GTHzjikThZx2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Hits'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Doubles'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Hits'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Doubles'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between hits and doubles in profesional baseball players\")\n",
        "plt.xlabel('Hits')\n",
        "plt.ylabel('Doubles')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M10Kwn_7px2Y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Batting Average'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Doubles'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Batting Average'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Doubles'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Batting Average and Doubles in profesional baseball players\")\n",
        "plt.xlabel('Batting Average')\n",
        "plt.ylabel('Doubles')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i73IBDARt_w-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These graphs have triples"
      ],
      "metadata": {
        "id": "hK-2wCkytFYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Hits'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Triples'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Hits'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Triples'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Hits and Triples in profesional baseball players\")\n",
        "plt.xlabel('Hits')\n",
        "plt.ylabel('Triples')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jBJ7HV2kqMCr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['At Bats'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Triples'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['At Bats'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Triples'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between at bats and Triples in profesional baseball players\")\n",
        "plt.xlabel('At Bats')\n",
        "plt.ylabel('Triples')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gX7n-U8GiNQD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Batting Average'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Triples'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Batting Average'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Triples'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Batting Average and Triples in profesional baseball players\")\n",
        "plt.xlabel('Batting Average')\n",
        "plt.ylabel('Triples')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yeSZVZchtzv9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These graphs have Home Runs"
      ],
      "metadata": {
        "id": "Q62P_3nMtMq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['At Bats'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Home Runs'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['At Bats'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Home Runs'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between at bats and Home Runs in profesional baseball players\")\n",
        "plt.xlabel('At Bats')\n",
        "plt.ylabel('Home Runs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jHp2Fb2ZijHz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Hits'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Home Runs'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Hits'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Home Runs'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Hits and Home Runs in profesional baseball players\")\n",
        "plt.xlabel('Hits')\n",
        "plt.ylabel('Home Runs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LEYuZh5crdLg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Batting Average'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Home Runs'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Batting Average'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Home Runs'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Batting Average and Home Runs in profesional baseball players\")\n",
        "plt.xlabel('Batting Average')\n",
        "plt.ylabel('Home Runs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kqnAAAktQrL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to see the spreads of HOF and Non HOF batting averages."
      ],
      "metadata": {
        "id": "l___Ofafxv1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hof = [df_one[df_one['Hall of Fame'] == i]['Batting Average'] for i in range(2)]\n",
        "\n",
        "plt.boxplot(hof, labels=['Non Hall of Fame','Hall of Fame'])\n",
        "\n",
        "plt.title(\"Batting Average distributions in HOF vs non HOF\")\n",
        "plt.ylabel('Batting Average')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L4sv-iFax2lu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hof = [df_one[df_one['Hall of Fame'] == i]['Hits'] for i in range(2)]\n",
        "\n",
        "plt.boxplot(hof, labels=['Non Hall of Fame','Hall of Fame'])\n",
        "\n",
        "plt.title(\"Hit distributions in HOF vs non HOF\")\n",
        "plt.ylabel('Hits')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-5_e8AOPz6-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AnT40PNBtzjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df_one[df_one['Hall of Fame'] == 1]['Games Played'],df_one[df_one['Hall of Fame'] == 1]\n",
        " ['Batting Average'], alpha = 0.5, color ='red', label = 'HOF')\n",
        "plt.scatter(df_one[df_one['Hall of Fame'] == 0]['Games Played'],df_one[df_one['Hall of Fame'] == 0]\n",
        " ['Batting Average'], alpha = 0.5, color= \"orange\", label = 'NON HOF')\n",
        "plt.title(\"The relationship between Years played and batting average in profesional baseball players\")\n",
        "plt.xlabel('Years Played')\n",
        "plt.ylabel('Batting Average')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pohuBCMlXeXH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to use some T-tests in order to figure out which variables have a signigicant effect on whether or not you make the Hall of Fame"
      ],
      "metadata": {
        "id": "NEO3nX_l40tN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n"
      ],
      "metadata": {
        "id": "OXGVZ0Hq7nj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#T-test for Batting Average.\n",
        "#Hypothesis- Batting Average affects entry into the HOF\n",
        "#Null Hypothesis- Batting average has no effect on HOF entry\n",
        "#P-Value< .05 to reject Null Hypothesis\n",
        "Hall_fame= df_one[df_one['Hall of Fame'] == 1]['Batting Average']\n",
        "non_fame= df_one[df_one[\"Hall of Fame\"] == 0]['Batting Average']\n",
        "t_stat, p_val= stats.ttest_ind(Hall_fame, non_fame)\n",
        "print(f\"T-Stat: {t_stat}, P-Value: {p_val}\\n\")\n",
        "\n",
        "if p_val > 0.05:\n",
        "    print(\"There is no statistically significant difference in batting averages.\")\n",
        "else:\n",
        "    print(\"There is a statistically significant difference between the batting averages.\")"
      ],
      "metadata": {
        "id": "Mft8znzy5Dhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#T-test for Hits\n",
        "#Hypothesis- number of hits affect entry into the HOF\n",
        "#Null Hypothesis- number of hits does not affect entry into the Hof\n",
        "#P-Value< .05 to reject the Null hypothesis\n",
        "Hall_fame= df_one[df_one['Hall of Fame'] == 1]['Hits']\n",
        "non_fame= df_one[df_one[\"Hall of Fame\"] == 0]['Hits']\n",
        "t_stat, p_val= stats.ttest_ind(Hall_fame, non_fame)\n",
        "print(f\"T-Stat: {t_stat}, P-Value: {p_val}\\n\")\n",
        "\n",
        "if p_val > 0.05:\n",
        "    print(\"There is no statistically significant difference between the hits.\")\n",
        "else:\n",
        "    print(\"There is a statistically significant difference between the hits.\")"
      ],
      "metadata": {
        "id": "85RlV0cV_g-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#T-test for Home Runs\n",
        "#Hypothesis-number of hits affect entry into the HOF\n",
        "#Null Hypothesis- number of hits does not affect entry into the HOF\n",
        "#P-value < .05 to reject the Null Hypothesis\n",
        "Hall_fame= df_one[df_one['Hall of Fame'] == 1]['Home Runs']\n",
        "non_fame= df_one[df_one[\"Hall of Fame\"] == 0]['Home Runs']\n",
        "t_stat, p_val= stats.ttest_ind(Hall_fame, non_fame)\n",
        "print(f\"T-Stat: {t_stat}, P-Value: {p_val}\\n\")\n",
        "\n",
        "if p_val > 0.05:\n",
        "    print(\"There is no statistically significant difference between the home runs.\")\n",
        "else:\n",
        "    print(\"There is a statistically significant difference between the hhome runs.\")"
      ],
      "metadata": {
        "id": "EpHeAP_AAU8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hall_fame= df_one[df_one['Hall of Fame'] == 1]['Games Played']\n",
        "non_fame= df_one[df_one[\"Hall of Fame\"] == 0]['Games Played']\n",
        "t_stat, p_val= stats.ttest_ind(Hall_fame, non_fame)\n",
        "print(f\"T-Stat: {t_stat}, P-Value: {p_val}\\n\")\n",
        "\n",
        "if p_val > 0.05:\n",
        "    print(\"There is no statistically significant difference between the games played.\")\n",
        "else:\n",
        "    print(\"There is a statistically significant difference between the games played.\")"
      ],
      "metadata": {
        "id": "MH07Lg1dBq4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Because every single value is giving me a low p-value, I am gonna\n",
        "#try seperating the HOF from non HOF and calculating averages to compare\n",
        "df_two = df_one.drop(columns = 'Player')\n",
        "hall_df= df_two[df_two['Hall of Fame']== 1]\n",
        "non_df= df_two[df_two[\"Hall of Fame\"] == 0]\n",
        "hall_df.mean()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JQDZOKABUkUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hall_df.info()"
      ],
      "metadata": {
        "id": "aZSYra0bYA26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_df.mean()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C7BInBEejhUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_df.info()"
      ],
      "metadata": {
        "id": "ELvqVht6YIOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Hits and batting average gave a pretty good seperation line between Hall of famers and non hall of famers, I am going to Use K nearest Neighbors with these two variables in order to predict who gets in the hall of fame"
      ],
      "metadata": {
        "id": "99vRPKhp9Ro8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standerdize data\n",
        "scaler = StandardScaler()\n",
        "df_bb = df_one.dropna()\n",
        "df_bb2 = scaler.fit_transform(df_bb[['Hits','Batting Average','Home Runs','Runs','Games Played','At Bats']])"
      ],
      "metadata": {
        "id": "5Kv0v9Srr2UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LrQSzpBimMeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bbstd.describe()"
      ],
      "metadata": {
        "id": "cg1P38Etm-If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bbstd = pd.DataFrame(df_bb2,columns = [\"Hits\",\"Batting Average\",\"Home Runs\",\"Runs\",\"Games Played\",\"At Bats\"])"
      ],
      "metadata": {
        "id": "ZWDwCaq6kkT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = df_bb[[\"Batting Average\",\"Hits\"]]\n",
        "label = df_bb[\"Hall of Fame\"]\n",
        "label"
      ],
      "metadata": {
        "id": "fgvjJQr7-Aba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(features, label, test_size= 0.2, random_state =42)"
      ],
      "metadata": {
        "id": "rA_O-Fis_JyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "lf4KEdi4_p6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbmodel = KNeighborsClassifier(n_neighbors= 4)"
      ],
      "metadata": {
        "id": "IBjhI0C0AAKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbmodel.fit(X_train, y_train)\n",
        "bbpredict = bbmodel.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bbpredict))"
      ],
      "metadata": {
        "id": "vr0V2LIiAOiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bbpredict)"
      ],
      "metadata": {
        "id": "h8G2k_h0BeFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "\n",
        "xx, yy = np.meshgrid(np.arange(1500, 4400, 0.1),\n",
        "                     np.arange(0.24,0.4, 0.1))\n",
        "z = bbmodel.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "z = z.reshape(xx.shape)\n",
        "\n",
        "ax.pcolormesh(xx, yy, z, alpha=0.1)\n",
        "\n",
        "for label, data in df_bb.groupby('Hall of Fame'):\n",
        "  ax.scatter(data[\"Hits\"], data[\"Batting Average\"], label=[\"No\",\"Yes\"][label], alpha=0.5)\n",
        "\n",
        "ax.set_title(\"Decision Boundary of the KNN Classifier\")\n",
        "ax.set_xlabel(\"mean radius\")\n",
        "ax.set_ylabel(\"mean texture\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZYvtKR3AZLA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am now going to try playing around with different K Values to see wich one is the most accurate."
      ],
      "metadata": {
        "id": "6ZNK5RVsDEa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "id": "MDCmls3iDcAI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best model visualization\n",
        "BBmodel = KNeighborsClassifier(n_neighbors= 11)\n",
        "BBmodel.fit(X_train, y_train)\n",
        "BBpredict = BBmodel.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,BBpredict))"
      ],
      "metadata": {
        "id": "kJlYpsUaA2H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "\n",
        "xx, yy = np.meshgrid(np.arange(1500, 4500, 10),\n",
        "                     np.arange(0.2, 0.4, 0.05))\n",
        "z = BBmodel.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "z = z.reshape(xx.shape)\n",
        "\n",
        "ax.pcolormesh(xx, yy, z, alpha=0.2)\n",
        "\n",
        "for label, data in df_bb.groupby('Hall of Fame'):\n",
        "  ax.scatter(data[\"Hits\"], data[\"Batting Average\"], label=[\"Non HOF\",\"HOF\"][label], alpha=0.5)\n",
        "\n",
        "ax.set_title(\"Decision Boundary of the KNN Classifier\")\n",
        "ax.set_xlabel(\"Hits\")\n",
        "ax.set_ylabel(\"Batting Average\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oVGou606BE8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,BBpredict)"
      ],
      "metadata": {
        "id": "DwR76UiwG5gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHTJ5vd-OySK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to make a new model this time with home runs added in"
      ],
      "metadata": {
        "id": "Phbew8IIEql-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresb = df_bb[[\"Hits\",\"Batting Average\",\"Home Runs\"]]\n",
        "labelb= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresb, labelb, test_size= 0.2, random_state =42)\n",
        "bbmodel3v = KNeighborsClassifier(n_neighbors= 49)\n",
        "bbmodel3v.fit(X_train, y_train)\n",
        "bb3vpredict = bbmodel3v.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bb3vpredict))"
      ],
      "metadata": {
        "id": "wFoFj-7VkYsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bb3vpredict)"
      ],
      "metadata": {
        "id": "ldtXqhDlll_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUhUooiInqb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,60,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "id": "ZawYXhJEnjqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is barely more accurate than the original so lets try getting rid of batting average"
      ],
      "metadata": {
        "id": "ac5Otw3Hkwsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresc = df_bb[[\"Hits\",\"Home Runs\"]]\n",
        "labelc= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresc, labelc, test_size= 0.2, random_state =42)\n",
        "bbmodelc = KNeighborsClassifier(n_neighbors= 4)\n",
        "bbmodelc.fit(X_train, y_train)\n",
        "bbpredictc = bbmodelc.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bbpredictc))"
      ],
      "metadata": {
        "id": "PzCP8Shpoe5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "id": "cKI8jfFXpcbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bbpredictc)"
      ],
      "metadata": {
        "id": "dHyN0fr1ZXAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its the same so lets just get rid of home Runs"
      ],
      "metadata": {
        "id": "Gy1agwKtqLl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresd = df_bb[[\"Hits\"]]\n",
        "labeld= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresd, labeld, test_size= 0.2, random_state =42)\n",
        "bbmodeld = KNeighborsClassifier(n_neighbors= 37)\n",
        "bbmodeld.fit(X_train, y_train)\n",
        "bbpredictd = bbmodeld.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bbpredictd))"
      ],
      "metadata": {
        "id": "kNH1hzeHqOyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPtKg8OCZGUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "id": "OhuLIqhoqbYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bbpredictd)"
      ],
      "metadata": {
        "id": "WZF9jt3QZl8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this model I will use batting average only"
      ],
      "metadata": {
        "id": "7VwzfolhbRVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresbat = df_bb[[\"Batting Average\"]]\n",
        "labelbat= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresbat, labelbat, test_size= 0.2, random_state =42)\n",
        "bbmodelbat = KNeighborsClassifier(n_neighbors= 11)\n"
      ],
      "metadata": {
        "id": "nTqZ0XFjbWcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbmodelbat.fit(X_train, y_train)\n",
        "bbpredictbat = bbmodelbat.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bbpredictbat))"
      ],
      "metadata": {
        "id": "uQbs5n51cJX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bbpredictbat)"
      ],
      "metadata": {
        "id": "d8WY-BJ5c8-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this model I will use runs only"
      ],
      "metadata": {
        "id": "7oHUP3kodXfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresrun = df_bb[[\"Runs\"]]\n",
        "labelrun= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresrun, labelrun, test_size= 0.2, random_state =42)\n",
        "bbmodelrun = KNeighborsClassifier(n_neighbors= 4)\n",
        "bbmodelrun.fit(X_train, y_train)\n",
        "bbpredictrun = bbmodelrun.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bbpredictrun))"
      ],
      "metadata": {
        "id": "aMTkxLAOd1fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jX__KTaXelkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model I will use all the variables I can possible use"
      ],
      "metadata": {
        "id": "aY3AOrM0e3Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresall = df_bb.drop(columns = ['Player','Hall of Fame','Batting Average','Doubles','Triples','Games Played'])\n",
        "labelall= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresall, labelall, test_size= 0.2, random_state =42)\n",
        "bbmodelall = KNeighborsClassifier(n_neighbors= 4)\n",
        "bbmodelall.fit(X_train, y_train)\n",
        "bbpredictall = bbmodelall.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bbpredictall))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5hZsuNgLe7Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bb.head()"
      ],
      "metadata": {
        "id": "MJmJ_oqXfRWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pSaFVIq3foaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bbpredictall)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k5556lNkgGSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am now going to remmake the models with the standardized data"
      ],
      "metadata": {
        "id": "kfAgtW9SngXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = df_bbstd[[\"Hits\",\"Batting Average\",]]\n",
        "label2= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(features2, label2, test_size= 0.2, random_state =42)\n",
        "bbmodel2 = KNeighborsClassifier(n_neighbors= 5)\n",
        "bbmodel2.fit(X_train, y_train)\n",
        "bb2predict = bbmodel2.predict(X_test)\n",
        "print(\"Accuracy Score: \", metrics.accuracy_score(y_test,bb2predict))"
      ],
      "metadata": {
        "id": "TySwsz4xnl5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bb2predict)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-qX6JwBCoFKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iND3FVfgoUmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Home Runs, Batting Average, Hits"
      ],
      "metadata": {
        "id": "VxT1v2XVsFfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresb = df_bbstd[[\"Hits\",\"Batting Average\",\"Home Runs\"]]\n",
        "labelb= df_bb[\"Hall of Fame\"]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(featuresb, labelb, test_size= 0.2, random_state =42)\n",
        "bbmodel3v = KNeighborsClassifier(n_neighbors= 5)\n",
        "bbmodel3v.fit(X_train, y_train)\n",
        "bb3vpredict = bbmodel3v.predict(X_test)\n",
        "print(\"Accuracy Score\", metrics.accuracy_score(y_test,bb3vpredict))"
      ],
      "metadata": {
        "id": "OutU2ChcpTPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.ConfusionMatrixDisplay.from_predictions(y_test,bb3vpredict)"
      ],
      "metadata": {
        "id": "2-zgIvyLqEvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for n in range(1,50,2):\n",
        "    full_model = KNeighborsClassifier(n_neighbors = n)\n",
        "    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "    pred = full_model.predict(X_test)\n",
        "    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "    scores[n] = score\n",
        "\n",
        "\n",
        "plt.title(\"Accuracy on Test set across K values\")\n",
        "print(scores)\n",
        "plt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n",
        "\n",
        "\n",
        "k = int(len(X_train)**(1/2)/2)*2 - 1\n",
        "full_model = KNeighborsClassifier(n_neighbors = k)\n",
        "full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n",
        "pred = full_model.predict(X_test)\n",
        "score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n",
        "plt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n",
        "\n",
        "\n",
        "top_score = max(scores.values())\n",
        "best_k = list(scores.keys())[list(scores.values()).index(top_score)]\n",
        "plt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# PRINTING THE RESULTS\n",
        "print(\"Top score of optimal classifier: \" + str(top_score))\n",
        "print(\"Optimal K \" + str(best_k))"
      ],
      "metadata": {
        "id": "lEHxxnAmqLH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}